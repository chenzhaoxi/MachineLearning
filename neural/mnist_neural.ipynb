{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification via a Neural Network\n",
    "\n",
    "In the the [MNIST SVM example](../svm/mnist_svm.ipynb), we introduced the classic MNIST digit classification problem and trained a simple SVM classifier for the model.  In this demo, we will try a simple neural network.  The network we will create will not perform quite as well -- we will obtain an accuracy of only around 97%, while the SVM classifier obtains an accuracy of over 98%.  However, once we understand these simple neural networks, we will be able to build more sophisticated networks that can obtain much better classification rate.  Also, in doing this demo, you will learn several important features of the `keras` package in addition to the concepts shown in the [simple neural network example](./synthetic.ipynb):\n",
    "\n",
    "* How to construct multi-class classifiers using categorical cross entropy.\n",
    "* How to optimize using mini-batches.\n",
    "* How to save and load the model after training.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Keras package and the MNIST data\n",
    "\n",
    "We first load the `keras` package as in the [simple neural network example](./synthetic.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load some other common packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get the MNIST data as in the [MNIST SVM example](../svm/mnist_svm.ipynb).  We rescale the input `X` from values from -1 to 1 as this works better for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "\n",
    "X = 2*(mnist.data/255-0.5)   # Change X from -1 to 1\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also split the data into traing and test.  A standard split uses 50,000 examples for training and 10,000 for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ntr = 50000\n",
    "nts = 10000\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X,y,train_size=ntr, test_size=nts,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use the `plt_digit` function from the [MNIST SVM example](../svm/mnist_svm.ipynb) to display digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABeCAYAAAAUjW5fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x212a4296a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plt_digit(x):\n",
    "    nrow = 28\n",
    "    ncol = 28\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "# Select random digits\n",
    "nplt = 4\n",
    "nsamp = X.shape[0]\n",
    "Iperm = np.random.permutation(nsamp)\n",
    "\n",
    "# Plot the images using the subplot command\n",
    "for i in range(nplt):\n",
    "    ind = Iperm[i]\n",
    "    plt.subplot(1,nplt,i+1)\n",
    "    plt_digit(X[ind,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Simple Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the neural network, we first import the appropriate sub-packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we clear the session.  As in the [simple neural network example](./synthetic.ipynb), this step is not necessary, but it is good practice as it clears any model layers that you have built before.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a very simple network.  The features are:\n",
    "*  We have one hidden layer with `nh=100` units.  \n",
    "*  One output layer with `nout=10` units, one for each of the 10 possible classes\n",
    "*  The output activation is `softmax`, which is used for multi-class targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nin = X.shape[1]  # dimension of input data\n",
    "nh = 100     # number of hidden units\n",
    "nout = int(np.max(y)+1)    # number of outputs = 10 since there are 10 classes\n",
    "model = Sequential()\n",
    "model.add(Dense(nh, input_shape=(nin,), activation='sigmoid', name='hidden'))\n",
    "model.add(Dense(nout, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the model summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden (Dense)               (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network\n",
    "\n",
    "As before, to train the network, we have to select an optimizer and a loss function.  Since this is a multi-class classification problem, we select the `sparse_categorial_crossentropy` loss.  We use the `adam` optimizer as before.  You may want to play with the learning rate `lr`.   We also set the `metrics` that we wish to track during the optimization.  In this case, we select `accuracy` on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension (-1) must be in the range [0, 2), where 2 is the number of dimensions in the input. for 'metrics/acc/ArgMax' (op: 'ArgMax') with input shapes: [?,10], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    669\u001b[0m           \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors_as_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m           status)\n\u001b[0m\u001b[0;32m    671\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    470\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension (-1) must be in the range [0, 2), where 2 is the number of dimensions in the input. for 'metrics/acc/ArgMax' (op: 'ArgMax') with input shapes: [?,10], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c6e76a3065e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m model.compile(optimizer=opt,\n\u001b[0;32m      5\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m               metrics=['accuracy'])\n\u001b[0m",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m                            **kwargs)\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    932\u001b[0m                         \u001b[0mappend_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mhandle_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[1;34m(metrics, weights)\u001b[0m\n\u001b[0;32m    929\u001b[0m                             metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[0;32m    930\u001b[0m                                                                \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m                                                                mask=masks[i])\n\u001b[0m\u001b[0;32m    932\u001b[0m                         \u001b[0mappend_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \"\"\"\n\u001b[0;32m    459\u001b[0m         \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36msparse_categorical_accuracy\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msparse_categorical_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     return K.cast(K.equal(K.max(y_true, axis=-1),\n\u001b[1;32m---> 32\u001b[1;33m                           K.cast(K.argmax(y_pred, axis=-1), K.floatx())),\n\u001b[0m\u001b[0;32m     33\u001b[0m                   K.floatx())\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m   1381\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \"\"\"\n\u001b[1;32m-> 1383\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(input, axis, name, dimension)\u001b[0m\n\u001b[0;32m    247\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot specify both 'axis' and 'dimension'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36marg_max\u001b[1;34m(input, dimension, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m   \"\"\"\n\u001b[0;32m    167\u001b[0m   result = _op_def_lib.apply_op(\"ArgMax\", input=input, dimension=dimension,\n\u001b[1;32m--> 168\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m    169\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    757\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    758\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2240\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2242\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2243\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2244\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1615\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1617\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1618\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1568\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1570\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    673\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension (-1) must be in the range [0, 2), where 2 is the number of dimensions in the input. for 'metrics/acc/ArgMax' (op: 'ArgMax') with input shapes: [?,10], []."
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001) # beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a simple method `fit` to run the optimization.  You simply specify the number of epochs and the batch size, both discussed in class.  In addition, we specify the `validation_data` so that it can print the accuracy on the test data set as it performs the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.5532 - acc: 0.8594 - val_loss: 0.3216 - val_acc: 0.9113\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.2769 - acc: 0.9205 - val_loss: 0.2459 - val_acc: 0.9275\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.2202 - acc: 0.9368 - val_loss: 0.2090 - val_acc: 0.9396\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.1842 - acc: 0.9471 - val_loss: 0.1785 - val_acc: 0.9494\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.1574 - acc: 0.9551 - val_loss: 0.1608 - val_acc: 0.9534\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.1362 - acc: 0.9612 - val_loss: 0.1392 - val_acc: 0.9594\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.1198 - acc: 0.9661 - val_loss: 0.1305 - val_acc: 0.9621\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.1067 - acc: 0.9700 - val_loss: 0.1277 - val_acc: 0.9612\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.0959 - acc: 0.9735 - val_loss: 0.1163 - val_acc: 0.9653\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0873 - acc: 0.9752 - val_loss: 0.1132 - val_acc: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27525ec92e8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr, ytr, epochs=10, batch_size=100, validation_data=(Xts,yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the 10 epochs, you should obtain a test accuracy of around 96.5%.  If we run it for another a few epochs, we can get slightly higher results.  We can just run the `model.fit` command again, and it will start where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0789 - acc: 0.9782 - val_loss: 0.1077 - val_acc: 0.9687\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0724 - acc: 0.9804 - val_loss: 0.1069 - val_acc: 0.9683\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0663 - acc: 0.9822 - val_loss: 0.0963 - val_acc: 0.9713\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0604 - acc: 0.9837 - val_loss: 0.0995 - val_acc: 0.9699\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0538 - acc: 0.9861 - val_loss: 0.0968 - val_acc: 0.9693\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0520 - acc: 0.9858 - val_loss: 0.0921 - val_acc: 0.9714\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0474 - acc: 0.9868 - val_loss: 0.0886 - val_acc: 0.9717\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0440 - acc: 0.9884 - val_loss: 0.0875 - val_acc: 0.9718\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.0393 - acc: 0.9903 - val_loss: 0.0872 - val_acc: 0.9732\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 3s - loss: 0.0381 - acc: 0.9901 - val_loss: 0.0875 - val_acc: 0.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27525fff588>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr, ytr, epochs=10, batch_size=100, validation_data=(Xts,yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a little more than 97% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading the model\n",
    "\n",
    "Since the training takes a long time, it is useful to save the results.  See the [keras page](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model) for many more useful saving and loading features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"mnist_mod.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reload the model with the `load_model` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden (Dense)               (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"mnist_mod.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the performance on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.971800\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(Xts, yts, verbose=0)\n",
    "print(\"accuracy = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
